{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Se tiene un archivo con 10 caracteres en total formado por tres caracteres distintos (ej:\n",
    "ABC). De todos los archivos posibles con estas características mostrar el archivo de máxima\n",
    "entropía que se pueda comprimir mejor usando LZ77. No es necesario comprimir el archivo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conseguir un archivo que tenga las caracteristicas que pide el enunciado necesitamos:\n",
    "1. Tenga cada simbolo con una probabilidad lo mas parecida posible, dado que la entropia se maximiza cuando todos los simbolos son equiprobables\n",
    "2. Que tenga repeticiones para que se comprima lo mejor posible en LZ77\n",
    "De 1. tenemos que el archivo va a tener 4 As, 3 Bs y 3 Cs. Y para que tenga repeticiones lo podemos ordenar de estas maneras:\n",
    "a. AAAABBBCCC --> 0A 1(0,3) 0B 1(0,2) 0C 1(0,2)\n",
    "b. ABCABCABCA --> 0A 0B 0C 1(2,7)\n",
    "\n",
    "Dado que tanto para el archivo \"a\" como para el \"b\" necesitamos 3 literales, definimos cual se comprime mejor en funcion de la cantidad de repeticiones que tenemos que codificar. Llegamos a la conclusion que el archivo \"b\" se comprime mejor porque LZ77 permite extender la ventana y hacer una sola repeticion de longitud 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Explique en que casos sería una buena idea usar un compresor aritmético estático de orden 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conviene utilizarlo si lo que queremos comprimir cumple:\n",
    "1. El archivo es muy grande, para compensar el tamanio de la tabla de frecuencias. (que ocupa 256^3 = 16MB)\n",
    "2. La longitud ideal de compresion (Entropia) no es entera en bits. Si fuera entero, **tendria** que ser equivalente comprimirlo con Huffman\n",
    "3. Si nuestra informacion esta estructurada de manera que saca provecho de los contextos de longitud 3. (Por ejemplo estructurada de a grupos de 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Tenemos un compresor aritmético dinámico de orden 0 que trabaja procesando bit por bit. Si\n",
    "comprimimos un archivo que está formado por una serie de 1000 bits en 1 y luego dos bits\n",
    "en 0. ¿cuántos bits ocupará el archivo comprimido?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-28.905998942643414\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "m.log2(2/1003)\n",
    "#Suma de las longitudes optimas\n",
    "r = 0\n",
    "for b in range(1000):\n",
    "    r += m.log2((1+b) / (2+b))\n",
    "r += m.log2(1/1002)\n",
    "r += m.log2(2/1003)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27.458510312536582"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Longitud final con las probabilidades\n",
    "h = (1000/1002)*m.log2(1000/1002) + (2/1002)*m.log2(2/10002)\n",
    "h*1002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.858893337059227\n",
      "8876.611123733346\n"
     ]
    }
   ],
   "source": [
    "#Entropia calculada con las probablidades paso a paso\n",
    "r = 0\n",
    "for b in range(1000):\n",
    "    r += -((1+b) / (2+b))*m.log2((1+b) / (2+b))\n",
    "r += -m.log2(1/1002)*(1/1002)\n",
    "r += -m.log2(2/1003)*(2/1003)\n",
    "\n",
    "print(r)\n",
    "print(r*1002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preguntar que pasa porque no lo sabemos resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Una planta industrial decidió instalar un sistema monitor de temperatura, a fin de obtener registro de las variaciones que existen, y poder tomar acciones de ser necesario. Dicho monitor cuenta con un sensor que emite cada 5 segundos un registro (fecha: AAAAMMDD, hora: HH:MM:SS, Temperatura: XX.XX, Variación: Numérico, puede ser positivo o negativo).**\n",
    "\n",
    "**Más allá de las acciones inmediatas que se puedan tomar, esta información se quiere almacenar para realizar consultas o análisis a futuro. Se pide proponer una solución que permita almacenar estos datos comprimidos. Se pueden utilizar uno o más algoritmos de los vistos en clase, o proponer variantes adaptadas a la estructura específica de los datos con los que se cuentan. Se debe explicar cómo queda la estructura final del archivo, y el análisis en el que se basó la solución.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Determinar si las siguientes afirmaciones son V / F justificando la respuesta:**\n",
    "- A. La entropia es una aproximacion de cuanto se puede comprimir, dado que no podemos calcular cuanto se puede comprimir un string\n",
    "- B. Una forma posible de comprimir un stream de datos es utilizar un huffman estático.\n",
    "- C. La entropia puede utilizarse para construir clasificadores de texto.\n",
    "- D. Un compresor estadistico estático comprime siempre mejor que un compresor estadístico dinámico.\n",
    "- E. Podemos determinar la longitud final del archivo comprimido utilizando huffman estático de orden 1, calculando la entropía y multiplicándola por la cantidad de caracteres del archivo.\n",
    "- F. Tenemos 2 archivos, uno con longitud pequeña y el otro muy grande que se comprimen utilizando huffman estático de orden 5. Si observamos que tienen la mismas tablas de frecuencias podemos afirmar que el cociente entre el tamaño del archivo sin comprimir y el tamaño del archivo comprimido será similar.\n",
    "- G. Todo archivo con complejidad de kolmogorov baja tendrá una entropía de Shannon baja.\n",
    "- H. Es imposible que un archivo comprimido mediante huffman estático de orden 1 iguale la máxima compresión dada por la entropía del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A: **VERDADERO** La compresión de un archivo es la representación del mismo en un volumen de datos menor. Permitiendo la generación del mismo a partir del archivo comprimido. La compresión optima esta relacionada con la complejidad de Kolmogorov del string, que nos será el archivo mas pequeño que genera mi string original. Dado que esta última no es codificable nos podemos saber cuanto se puede comprimir un string de manera absoluta, solo podemos hacer aproximaciones.  \n",
    "    La entropía nos da una aproximación a la major compresión estadística que se puede realizar, dado que nos da el promedio de la longitud optima en bits de cada simbolo del archivo (o para cada mensaje en un stream de comunicacion). Y si calculamos el numero de simbolos del archivo por la entropía nos dará la longitud optima en bts del archivo comprimido estadísticamente.  \n",
    "- B: **FALSO** Dado que el Huffman estático requiere recorrer todos los datos para calcular la frecuencia de todos los simbolos (es decir, para comprimir hace dos pasadas: 1 para contar frecuencias y otra para comprimir). Esto imposible en un stream de datos, donde no conocemos al momento de comprimir que otros simbolos tendremos que comprimir a continuación. En cambio si se podría con Huffman dinámico, comenzando suponiendo todos los caracteres como equiprobables y luego actualizando las frecuencias  (y por ende las probabilidades) de los símbolos a medida que se comprime los simbolos que se reciben del stream.\n",
    "- C: **FALSO** La entropía es una medida de incertidumbre en un archivo. Y nos otorga la longitud promedio optima en bits que necesitaríamos para representar cada simbolo en el archivo. Pero esto no nos sirve para realizar un clasificador.  \n",
    "     Se podría hacer un clasificador para textos que comparten el mismo numero numero de entropia. Pero dado que la entropia solo depende de las probabilidades en el texto (osea de las frecuencias de sus caracteres y NO de su orden en el), todos los \"anagramas\" de un texto serían clasificados de forma equivalente aunque no tuvieran sentido en el lenguaje. (El texto: \"GUSANO\" y \"OSNAUG\" tendrán la misma entropía y clasificados igual, y sin embargo el segundo carece de sentido).  \n",
    "    En contraposición, un compresor si nos serviría para realizar un clasificador. Entrenando un compresor que pese varios modelos de compresion con un tipo en particular de archivos (por ejemplo noticias). Luego repetimos proceso con otro tipo de archivos (novelas), luego a un archivo nuevo lo comprimimos con ambos, y el que comprima mejor nos dara la directiva de como clasificarlo. \n",
    "- D: **DEPENDE** Dado que el estático ya calcula las probabilidades de todos los simbolos desde el comienzo de la compresión entonces asigna un espacio menor a los que son mas frecuentes. En cambio los dinámicos asumen equiprobabilidad y la ajustan a medida que comprimen, por lo tanto las primeras apariciones de datos mas frecuentes no se comprimen lo mejor posible.  \n",
    "    De todas maneras es importante tener en cuenta que la desventaja de los compresores estáticos es que deben guardar la tabla en el archivo comprimido. En archivos pequeños el tamaño de la tabla podría ser relevante haciendo que sea conveniente usar un compresor dinámico. Para sumar a este problema si se quiere comprimir con un orden mayor el tamaño de las tablas aumenta exponencialmente.\n",
    "- E: **FALSO** Porque la entropía nos da la longitud promedio **en bits** de cada simbolo en el string. Y dado que Huffman no puede comprimir un simbolo cantidades no enteras de bits, no se puede  calcular la longitud del archivo comprimido haciendo entropía*#catacteres. En cambio, la entropía si es una buena aproximación de cuanto ocupará el archivo comprimido con compresión aritmética, dado que esta si permite comprimir un simbolo en menos de 1 bit.\n",
    "\n",
    "Esto funciona si las longitudes optimas de cada simbolo en el archivo son enteras ( -log2(Pi) ), ahora podría suceder que la entropía no de entera y que las codificaciones si lo sean? Si ese es el caso, Huffman sería óptimo? Y se podría calcular la longitud de el archivo haciendo entropía * #simbolos ? \n",
    "- F: NI IDEA\n",
    "- GG: **FALSO** Porque la entropía está relacionada a la probabilidad de los caractereres, un archivo equiprobable tendrá entropía máxima y sin embargo puede poder representarse en pocos bits, tienendo un K(x) bajo.  \n",
    "    Un ejemplo puede ser el archivo: ABCABCABC que tiene todos sus caracteres equiprobables y por ende entropía máxima y se comprime muy bien utilizando un algoritmo de compresion por repeticion como LZ77 dado que tiene la secuencia ABC repetida 3 veces. Pudiendo entonces representarse en muchos menos bytes al estar comprimido (bajo K(x)).\n",
    "- h: **FALSO** Ni idea porque dice de orden 1...  \n",
    "    En el caso que el archivo tenga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
