{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"Guia Spark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1- Se tiene un RDD con el registro de notas de los alumnos de la forma (padrón, materia, nota,\n",
    "fecha). Se pide resolver utilizando PySpark:**\n",
    "- A. Cuántos alumnos aprobaron al menos 1 materia en los últimos 2 años.\n",
    "- B. Un RDD conteniendo el promedio de notas de cada alumno de la forma (padrón, promedio).\n",
    "- C. El nombre y apellido del alumno con mejor promedio. Para esto puede utilizarse un segundo RDD alumnos con registros (padron, nombre y apellido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10042', 'Quimica', '5', '02/17/2018'],\n",
       " ['10074', 'Algo1', '1', '12/15/2017'],\n",
       " ['10099', 'Analisis II', '2', '12/02/2018'],\n",
       " ['10024', 'Algo2', '7', '08/15/2017'],\n",
       " ['10098', 'Taller de programacion', '6', '05/20/2017'],\n",
       " ['10015', 'Analisis II', '5', '09/09/2018'],\n",
       " ['10037', 'Quimica', '1', '04/21/2019'],\n",
       " ['10013', 'Quimica', '10', '05/29/2019'],\n",
       " ['10062', 'Analisis II', '9', '04/12/2017'],\n",
       " ['10060', 'Algo3', '4', '10/11/2017']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notas = sc.textFile(\"ej1.csv\").map(lambda x: x.split(','))\n",
    "notas.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A\n",
    "#  0       1        2      3\n",
    "#[ padron, materia, nota, fecha ]\n",
    "aprobadas_ultimos_2_anios = notas.filter(lambda x: (int(x[2])>=4) & (x[3]>\"01/01/2017\"))\n",
    "aprobadas_ultimos_2_anios.map(lambda x: x[0]).distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10042', 5.0],\n",
       " ['10074', 1.0],\n",
       " ['10099', 2.0],\n",
       " ['10024', 7.0],\n",
       " ['10098', 6.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B\n",
    "#armo un RDD de la forma [padron, [nota, 1]]\n",
    "alumno_nota = notas.map(lambda x: [x[0], [int(x[2]), 1]])\n",
    "alumno_nota.reduceByKey(lambda x,y: [x[1][0] + y[1][0], x[1][1] + y[1][1]])\n",
    "alumno_promedio = alumno_nota.map(lambda x: [x[0], x[1][0]/x[1][1]])\n",
    "alumno_promedio.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10070', 'Esmaria Koppelmann'],\n",
       " ['10000', 'Lu Peinke'],\n",
       " ['10029', 'Kristyn Timlin'],\n",
       " ['10000', 'Phillip Boxer'],\n",
       " ['10051', 'Adrea Le Borgne']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nombres = sc.textFile(\"ej1_nombres.csv\").map(lambda x: x.split(','))\n",
    "nombres.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10002', 'Kai Jammet'],\n",
       " ['10002', 'Arney Lathwell'],\n",
       " ['10002', 'Karel Richel'],\n",
       " ['10002', 'Eudora De Micoli'],\n",
       " ['10002', 'Keefe MacPaik'],\n",
       " ['10002', 'Marleen Loxdale'],\n",
       " ['10002', 'Prent Silliman'],\n",
       " ['10002', 'Kelby Leppard'],\n",
       " ['10002', 'Neal Fenne'],\n",
       " ['10002', 'Mario Frowen'],\n",
       " ['10002', 'Dedra Coston'],\n",
       " ['10002', 'Carol Whitman'],\n",
       " ['10002', 'Salomo Valeri'],\n",
       " ['10002', 'Cchaddie Whitehurst'],\n",
       " ['10002', 'Amory Gleadhall'],\n",
       " ['10002', 'Lesley Crowhurst'],\n",
       " ['10002', 'Dominic Giraudoux'],\n",
       " ['10002', 'Amalie Gile'],\n",
       " ['10002', 'Rosalinda MacAdie']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C\n",
    "alumno_mejor_promedio = alumno_promedio.reduce(lambda x,y: x if x[1]>y[1] else y)\n",
    "nombre_alumno_mejor_promedio = nombres.filter(lambda x: x[0] == alumno_mejor_promedio[0])\n",
    "nombre_alumno_mejor_promedio.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2- Se tiene un RDD registros de ventas de producto con la forma (fecha de venta, código de\n",
    "producto, precio de venta) y en otro RDD detalle de los productos con (código de producto,\n",
    "descripción del producto, categoría). Se pide resolver utilizando PySpark:**\n",
    "- A. Cuál es el producto más vendido.\n",
    "- B. Cuál es la categoría de productos más vendida.\n",
    "- C. Cuál es el top5 de productos más vendidos generando un RDD con (código de producto, descripción, cantidad de ventas)\n",
    "- D. Cuál es el producto que registró mayor aumento de precio en el último año, tomando para este análisis solo los productos que cuenten con al menos 50 ventas en el último año.\n",
    "- E. Idem anterior, pero calculando la categoría de productos que registró mayor variación de precios en el último año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['11/04/2019', '20', '338'],\n",
       " ['12/09/2019', '1', '412'],\n",
       " ['07/10/2019', '61', '395']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ventas = sc.textFile(\"ej2.csv\").map(lambda x: x.split(','))\n",
    "productos = sc.textFile(\"ej2_productos.csv\").map(lambda x: x.split(','))\n",
    "ventas.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'quis tortor id nulla', 'Computacion'],\n",
       " ['2', 'et tempus semper est quam', 'Comida'],\n",
       " ['3', 'sed tristique in tempus sit amet sem', 'Computacion']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productos.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('71', 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A\n",
    "cant_vendidos = ventas.map(lambda x: (x[1], 1)).reduceByKey(lambda x,y: x+y)\n",
    "cant_vendidos.reduce(lambda x,y: x if x[1]>=y[1] else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Utileria'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B\n",
    "ventas_ind_prod = ventas.map(lambda x: (x[1],1))\n",
    "ventas_cat = productos.map(lambda x: (x[0],x[2])).join(ventas_ind_prod)\n",
    "ventas_x_cat = ventas_cat.map(lambda x: (x[1][0], x[1][1])).reduceByKey(lambda x,y: x+y)\n",
    "ventas_x_cat.reduce(lambda x,y: x if x[1]>= y[1] else y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['71', 'nam congue risus semper porta volutpat quam pede', 17],\n",
       " ['65', 'id pretium iaculis diam', 16],\n",
       " ['17', 'mauris eget massa tempor', 15],\n",
       " ['68', 'diam vitae quam suspendisse potenti nullam porttitor lacus at', 15],\n",
       " ['77',\n",
       "  'est lacinia nisi venenatis tristique fusce congue diam id ornare',\n",
       "  15]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C\n",
    "cant_vendidos_c_descr = productos.map(lambda x: (x[0], x[1])).join(cant_vendidos)\n",
    "cant_vendidos_c_descr.map(lambda x: [x[0],x[1][0], x[1][1]]).takeOrdered(5, lambda x: -x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este punto debería ser el precio del año anterior menos el precio del año pasado y asi obtener la diferencia no del minimo menos el maximo.\n",
    "\n",
    "Como takeOrdered devuelve una lista! Tenemos que hacer el Map para ordenarlo de la manera que lo queremos antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('56', 442)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#D\n",
    "ventas_ultimo_año = ventas.filter(lambda x: (x[0]>=\"01/01/2019\") & (x[0]<=\"31/12/2019\"))\n",
    "ventas_mas_50 = ventas_ultimo_año.map(lambda x: (x[1], 1)).reduceByKey(lambda x,y: x+y).filter(lambda x: x[1]>= 10) # Lo cambio a 10 por el set de datos\n",
    "ventas_formateado = ventas.map(lambda x: (x[1], int(x[2]))) #[id, precio]\n",
    "ventas_mas_50_completo = ventas_formateado.join(ventas_mas_50).map(lambda x: (x[0], x[1][0]))\n",
    "#[id, precio]\n",
    "#minimos = ventas_mas_50_completo.reduceByKey(lambda x,y: x if x<=y else y)\n",
    "minimos = ventas_mas_50_completo.reduceByKey(min)\n",
    "#maximos = ventas_mas_50_completo.reduceByKey(lambda x,y: x if x>=y else y)\n",
    "maximos = ventas_mas_50_completo.reduceByKey(max)\n",
    "minimos_y_maximos = minimos.join(maximos) #[id, (min, max)]\n",
    "diferencia = minimos_y_maximos.map(lambda x: (x[0], x[1][1]- x[1][0]))\n",
    "diferencia.reduce(lambda x,y: x if x[1]>y[1] else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E te la debo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3- Se tiene un RDD con información de vuelos programados con la forma (número de vuelo,\n",
    "código de aerolínea, código de aeropuerto de salida, código de aeropuerto de llegada, fecha de\n",
    "salida AAAAMMDD, hora de salida HH:MM, fecha de llegada AAAAMMDD, hora de llegada\n",
    "HH:MM). A su vez, se cuenta con el registro actualizado del estado de los vuelos que fueron\n",
    "ocurriendo, con la forma (número de vuelo, aerolínea, fecha de salida AAAAMMDD, hora de\n",
    "salida HH:MM, fecha de llegada AAAAMMDD, hora de llegada HH:MM, estado). En base al\n",
    "estado, podría contar con algún dato en blanco, por ejemplo si el vuelo fue cancelado no tendrá\n",
    "información de fechas y horas, si el vuelo se encuentra aún en curso, no contendrá información\n",
    "de la llegada. Se pide resolver utilizando PySpark:**\n",
    "- A. Cuál es el aeropuerto con mayor tránsito.\n",
    "- B. Cuál es la aerolínea con mayor cantidad de vuelos.\n",
    "- C. Cuál es la aerolínea con mayor cantidad de cancelaciones.\n",
    "- D. Cuál es el vuelo (numero de vuelo + fecha) con mayor retraso en el horario de salida.\n",
    "- E. Cuál es el vuelo (numero de vuelo + fecha) con mayor retraso en el horario de llegada.\n",
    "- F. Cuál es la aerolínea más puntual.\n",
    "- G. Cuál es el aeropuerto que registra mayor desviación con respecto a los horarios coordinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(número de vuelo, código de aerolínea, código de aeropuerto de salida, código de aeropuerto de llegada,\n",
    "#fecha de salida AAAAMMDD, hora de salida HH:MM, fecha de llegada AAAAMMDD, hora de llegada HH:MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay chance que haga un csv para esto. Se hace en papel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4- Se tiene un RDD con las coordenadas de rectángulos de la forma (x1,x2,y1,y2). Se pide\n",
    "programar en PySpark un programa que encuentre el rectángulo de superficie mínima que\n",
    "contiene al punto (w,z)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[87, 11, 52, 40],\n",
       " [81, 93, 23, 4],\n",
       " [58, 52, 85, 11],\n",
       " [87, 76, 19, 54],\n",
       " [37, 38, 70, 59]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rectangulos = sc.textFile(\"ej4.csv\").map(lambda x: [int(n) for n in x.split(\",\")])\n",
    "rectangulos.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[x1, x2, y1, y2]\n",
    "punto = (25,25) #(w,z) \n",
    "#w in [x1,x2] , z in [y1, y2]\n",
    "def contiene_p(r):\n",
    "    x1, x2, y1, y2 = r\n",
    "    contiene_x = (punto[0] > x1) and (punto[0]<x2)\n",
    "    contiene_y = (punto[1] > y1) and (punto[1]<y2)\n",
    "    return contiene_x and contiene_y\n",
    "rectangulos_contienen_punto = rectangulos.filter(contiene_p)\n",
    "segmentos = rectangulos_contienen_punto.map(lambda x: (abs(x[0]-x[1]), abs(x[2]- x[3])))\n",
    "areas = segmentos.map(lambda x: x[0]*x[1])\n",
    "areas.reduce(lambda x,y: x if x<y else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5- Se tiene un RDD con libros en donde cada registro es un texto. Se pide obtener todos los anagramas de mas de 7 letras que puedan encontrarse. El formato de salida debe ser una lista de listas en donde cada lista tiene un conjunto de palabras que son anagramas.** Ejemplo:\n",
    "[[discounter,introduces,reductions],[percussion,supersonic]...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"ACT I\"']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos = sc.textFile(\"alllines.txt\")\n",
    "textos.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alo', 'loa'], ['loa', 'alo']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ACT', 'I', 'SCENE', 'I', 'London']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def es_anagrama(palabra, palabra_2):\n",
    "    if len(palabra) != len(palabra_2) or palabra == palabra_2:\n",
    "        return False\n",
    "    for letra in palabra:\n",
    "        if letra not in palabra_2:\n",
    "            return False\n",
    "    for letra in palabra_2:\n",
    "        if letra not in palabra:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def crear_anagramas(lista):\n",
    "    anagramas = []\n",
    "    for palabra in lista:\n",
    "        anagramas_actuales = []\n",
    "        anagramas_actuales.append(palabra)\n",
    "        for palabra2 in lista:\n",
    "            if es_anagrama(palabra, palabra2):\n",
    "                anagramas_actuales.append(palabra2)\n",
    "        if len(anagramas_actuales) > 1:\n",
    "            anagramas.append(anagramas_actuales)\n",
    "    return anagramas\n",
    "print(crear_anagramas([\"alo\", \"a\", \"loa\", \"al\"]))\n",
    "palabras = textos.flatMap(lambda x: x.split(' ')).map(lambda x: x.strip('\"-!?,´.:').strip(\"'\"))\n",
    "palabras.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LANCASTER', 'WESTMORELAND', 'frighted', 'short-winded', 'commenced']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_mas_7_letras = palabras.filter(lambda x: len(x)>7)\n",
    "palabras_mas_7_letras.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palabras_mas_4_letras.map(lambda x: (len(x), [x])).reduceByKey(lambda x,y: x+y)\n",
    "#palabras_mas_7_letras.distinct().map(lambda x: (len(x), x)).groupByKey().map(lambda x: crear_anagramas(list(x[1]))).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mischance', 'mechanics'],\n",
       " ['brawling', 'warbling'],\n",
       " ['unsorted', 'roundest'],\n",
       " ['converse', 'conserve'],\n",
       " ['dropsies', 'disposer']]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_mas_7_letras.distinct().map(lambda x: (\"\".join(sorted(x)), x)).groupByKey()\\\n",
    "    .map(lambda x: list(x[1])).filter(lambda x: len(x)>1).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
