{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"Guia Spark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1- Se tiene un RDD con el registro de notas de los alumnos de la forma (padrón, materia, nota,\n",
    "fecha). Se pide resolver utilizando PySpark:**\n",
    "- A. Cuántos alumnos aprobaron al menos 1 materia en los últimos 2 años.\n",
    "- B. Un RDD conteniendo el promedio de notas de cada alumno de la forma (padrón, promedio).\n",
    "- C. El nombre y apellido del alumno con mejor promedio. Para esto puede utilizarse un segundo RDD alumnos con registros (padron, nombre y apellido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10042', 'Quimica', '5', '02/17/2018'],\n",
       " ['10074', 'Algo1', '1', '12/15/2017'],\n",
       " ['10099', 'Analisis II', '2', '12/02/2018'],\n",
       " ['10024', 'Algo2', '7', '08/15/2017'],\n",
       " ['10098', 'Taller de programacion', '6', '05/20/2017'],\n",
       " ['10015', 'Analisis II', '5', '09/09/2018'],\n",
       " ['10037', 'Quimica', '1', '04/21/2019'],\n",
       " ['10013', 'Quimica', '10', '05/29/2019'],\n",
       " ['10062', 'Analisis II', '9', '04/12/2017'],\n",
       " ['10060', 'Algo3', '4', '10/11/2017']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notas = sc.textFile(\"ej1.csv\").map(lambda x: x.split(','))\n",
    "notas.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A\n",
    "#  0       1        2      3\n",
    "#[ padron, materia, nota, fecha ]\n",
    "aprobadas_ultimos_2_anios = notas.filter(lambda x: (int(x[2])>=4) & (x[3]>\"01/01/2017\"))\n",
    "aprobadas_ultimos_2_anios.map(lambda x: x[0]).distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10042', 5.0],\n",
       " ['10074', 1.0],\n",
       " ['10099', 2.0],\n",
       " ['10024', 7.0],\n",
       " ['10098', 6.0]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B\n",
    "#armo un RDD de la forma [padron, [nota, 1]]\n",
    "alumno_nota = notas.map(lambda x: [x[0], [int(x[2]), 1]])\n",
    "alumno_nota.reduceByKey(lambda x,y: [x[1][0] + y[1][0], x[1][1] + y[1][1]])\n",
    "alumno_promedio = alumno_nota.map(lambda x: [x[0], x[1][0]/x[1][1]])\n",
    "alumno_promedio.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10070', 'Esmaria Koppelmann'],\n",
       " ['10000', 'Lu Peinke'],\n",
       " ['10029', 'Kristyn Timlin'],\n",
       " ['10000', 'Phillip Boxer'],\n",
       " ['10051', 'Adrea Le Borgne']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nombres = sc.textFile(\"ej1_nombres.csv\").map(lambda x: x.split(','))\n",
    "nombres.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10002', 'Kai Jammet'],\n",
       " ['10002', 'Arney Lathwell'],\n",
       " ['10002', 'Karel Richel'],\n",
       " ['10002', 'Eudora De Micoli'],\n",
       " ['10002', 'Keefe MacPaik'],\n",
       " ['10002', 'Marleen Loxdale'],\n",
       " ['10002', 'Prent Silliman'],\n",
       " ['10002', 'Kelby Leppard'],\n",
       " ['10002', 'Neal Fenne'],\n",
       " ['10002', 'Mario Frowen'],\n",
       " ['10002', 'Dedra Coston'],\n",
       " ['10002', 'Carol Whitman'],\n",
       " ['10002', 'Salomo Valeri'],\n",
       " ['10002', 'Cchaddie Whitehurst'],\n",
       " ['10002', 'Amory Gleadhall'],\n",
       " ['10002', 'Lesley Crowhurst'],\n",
       " ['10002', 'Dominic Giraudoux'],\n",
       " ['10002', 'Amalie Gile'],\n",
       " ['10002', 'Rosalinda MacAdie']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C\n",
    "alumno_mejor_promedio = alumno_promedio.reduce(lambda x,y: x if x[1]>y[1] else y)\n",
    "nombre_alumno_mejor_promedio = nombres.filter(lambda x: x[0] == alumno_mejor_promedio[0])\n",
    "nombre_alumno_mejor_promedio.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2- Se tiene un RDD registros de ventas de producto con la forma (fecha de venta, código de\n",
    "producto, precio de venta) y en otro RDD detalle de los productos con (código de producto,\n",
    "descripción del producto, categoría). Se pide resolver utilizando PySpark:**\n",
    "- A. Cuál es el producto más vendido.\n",
    "- B. Cuál es la categoría de productos más vendida.\n",
    "- C. Cuál es el top5 de productos más vendidos generando un RDD con (código de producto, descripción, cantidad de ventas)\n",
    "- D. Cuál es el producto que registró mayor aumento de precio en el último año, tomando para este análisis solo los productos que cuenten con al menos 50 ventas en el último año.\n",
    "- E. Idem anterior, pero calculando la categoría de productos que registró mayor variación de precios en el último año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['11/04/2019', '20', '338'],\n",
       " ['12/09/2019', '1', '412'],\n",
       " ['07/10/2019', '61', '395']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ventas = sc.textFile(\"ej2.csv\").map(lambda x: x.split(','))\n",
    "productos = sc.textFile(\"ej2_productos.csv\").map(lambda x: x.split(','))\n",
    "ventas.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'quis tortor id nulla', 'Computacion'],\n",
       " ['2', 'et tempus semper est quam', 'Comida'],\n",
       " ['3', 'sed tristique in tempus sit amet sem', 'Computacion']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productos.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('71', 17)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A\n",
    "cant_vendidos = ventas.map(lambda x: (x[1], 1)).reduceByKey(lambda x,y: x+y)\n",
    "cant_vendidos.reduce(lambda x,y: x if x[1]>=y[1] else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Utileria'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B\n",
    "ventas_ind_prod = ventas.map(lambda x: (x[1],1))\n",
    "ventas_cat = productos.map(lambda x: (x[0],x[2])).join(ventas_ind_prod)\n",
    "ventas_x_cat = ventas_cat.map(lambda x: (x[1][0], x[1][1])).reduceByKey(lambda x,y: x+y)\n",
    "ventas_x_cat.reduce(lambda x,y: x if x[1]>= y[1] else y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['71', 'nam congue risus semper porta volutpat quam pede', 17],\n",
       " ['65', 'id pretium iaculis diam', 16],\n",
       " ['17', 'mauris eget massa tempor', 15],\n",
       " ['68', 'diam vitae quam suspendisse potenti nullam porttitor lacus at', 15],\n",
       " ['77',\n",
       "  'est lacinia nisi venenatis tristique fusce congue diam id ornare',\n",
       "  15]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C\n",
    "cant_vendidos_c_descr = productos.map(lambda x: (x[0], x[1])).join(cant_vendidos)\n",
    "cant_vendidos_c_descr.map(lambda x: [x[0],x[1][0], x[1][1]]).takeOrdered(5, lambda x: -x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como takeOrdered devuelve una lista! Tenemos que hacer el Map para ordenarlo de la manera que lo queremos antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
