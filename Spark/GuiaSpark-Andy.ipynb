{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1- Se tiene un RDD con el registro de notas de los alumnos de la forma (padrón, materia, nota,\n",
    "fecha). Se pide resolver utilizando PySpark:**\n",
    "- A. Cuántos alumnos aprobaron al menos 1 materia en los últimos 2 años.\n",
    "- B. Un RDD conteniendo el promedio de notas de cada alumno de la forma (padrón, promedio).\n",
    "- C. El nombre y apellido del alumno con mejor promedio. Para esto puede utilizarse un segundo RDD alumnos con registros (padron, nombre y apellido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10042', 'Quimica', '5', '02/17/2018'],\n",
       " ['10074', 'Algo1', '1', '12/15/2017'],\n",
       " ['10099', 'Analisis II', '2', '12/02/2018'],\n",
       " ['10024', 'Algo2', '7', '08/15/2017'],\n",
       " ['10098', 'Taller de programacion', '6', '05/20/2017'],\n",
       " ['10015', 'Analisis II', '5', '09/09/2018'],\n",
       " ['10037', 'Quimica', '1', '04/21/2019'],\n",
       " ['10013', 'Quimica', '10', '05/29/2019'],\n",
       " ['10062', 'Analisis II', '9', '04/12/2017'],\n",
       " ['10060', 'Algo3', '4', '10/11/2017']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile(\"ej1.csv\").map(lambda x: x.split(','))\n",
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El ultimo anio, aprobaron 101 alumnos\n"
     ]
    }
   ],
   "source": [
    "aprobadosUltimoAnio = data.filter(lambda x: (int(x[2])>=4) & (x[3]>\"01/01/2017\") )\n",
    "cant_aprobados = aprobadosUltimoAnio.map(lambda x: x[0]).distinct().count()\n",
    "print(\"El ultimo anio, aprobaron %d alumnos\"%cant_aprobados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10042', 4.7272727272727275),\n",
       " ('10099', 4.090909090909091),\n",
       " ('10098', 5.076923076923077),\n",
       " ('10015', 5.25),\n",
       " ('10037', 5.133333333333334)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porAlumno = data.map(lambda x: (x[0],(int(x[2]),1)))\n",
    "promPorAlumno = porAlumno.reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1])).map(lambda x:(x[0],x[1][0]/x[1][1]))\n",
    "promPorAlumno.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El nombre del alumno con mejor promedio es Mirella Rosten, con promedio 8.50 \n"
     ]
    }
   ],
   "source": [
    "nombres = sc.textFile(\"ej1_nombres.csv\").map(lambda x: x.split(','))\n",
    "joined = promPorAlumno.join(nombres)\n",
    "mayorPromedio = joined.reduce(lambda x,y: x if x[1]>y[1] else y)\n",
    "print(\"El nombre del alumno con mejor promedio es %s, con promedio %.2f \"%(mayorPromedio[1][1],mayorPromedio[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Se tiene un RDD registros de ventas de producto con la forma (fecha de venta, código de\n",
    "producto, precio de venta) y en otro RDD detalle de los productos con (código de producto,\n",
    "descripción del producto, categoría). Se pide resolver utilizando PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['11/04/2019', '20', '338'],\n",
       " ['12/09/2019', '1', '412'],\n",
       " ['07/10/2019', '61', '395'],\n",
       " ['09/26/2019', '94', '52'],\n",
       " ['11/03/2019', '88', '216']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ventas = sc.textFile('ej2.csv').map(lambda x: x.split(','))\n",
    "detalle = sc.textFile('ej2_productos.csv').map(lambda x: x.split(','))\n",
    "ventas.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Cuál es el producto más vendido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20', (7, 'neque aenean auctor gravida sem praesent id massa')),\n",
       " ('88', (12, 'enim in tempor turpis nec euismod scelerisque quam')),\n",
       " ('77',\n",
       "  (15, 'est lacinia nisi venenatis tristique fusce congue diam id ornare')),\n",
       " ('10', (9, 'aliquam non mauris morbi non lectus aliquam sit amet diam')),\n",
       " ('40', (13, 'laoreet ut rhoncus'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productos = ventas.map(lambda x: (x[1],1) )\n",
    "porProducto = productos.reduceByKey(lambda x,y:x+y)\n",
    "joined = porProducto.join(detalle)\n",
    "joined.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El producto mas vendido es nam congue risus semper porta volutpat quam pede, con 17 unidades\n"
     ]
    }
   ],
   "source": [
    "prodMasVendido = joined.reduce(lambda x,y: x if x[1][0] > y[1][0] else y)\n",
    "print(\"El producto mas vendido es %s, con %d unidades\"%(prodMasVendido[1][1],prodMasVendido[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Cuál es la categoría de productos más vendida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La categoria mas vendida es Computacion\n"
     ]
    }
   ],
   "source": [
    "porCategoria = detalle.map(lambda x: (x[2],1)).reduceByKey(lambda x,y:x+y)\n",
    "maxCategoria = porCategoria.reduce(lambda x,y: x if x[1]>y[1] else y)\n",
    "print(\"La categoria mas vendida es %s\"%maxCategoria[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Cuál es el top5 de productos más vendidos generando un RDD con (código de\n",
    "producto, descripción, cantidad de ventas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('71', 'nam congue risus semper porta volutpat quam pede', 17),\n",
       " ('65', 'id pretium iaculis diam', 16),\n",
       " ('77',\n",
       "  'est lacinia nisi venenatis tristique fusce congue diam id ornare',\n",
       "  15),\n",
       " ('80',\n",
       "  'mauris viverra diam vitae quam suspendisse potenti nullam porttitor lacus',\n",
       "  15),\n",
       " ('15', 'ante ipsum primis in faucibus', 15)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descripciones = detalle.map(lambda x: (x[0],x[1]))\n",
    "joined_prod_desc = porProducto.join(detalle)\n",
    "joined_prod_desc.take(5)\n",
    "top5prod = joined_prod_desc.map(lambda x: (x[0],x[1][1],x[1][0])).takeOrdered(5, lambda x: -x[2])\n",
    "top5RDD = sc.parallelize(top5prod)\n",
    "top5RDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. Cuál es el producto que registró mayor aumento de precio en el último año, tomando\n",
    "para este análisis solo los productos que cuenten con al menos 50 ventas en el último\n",
    "año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El producto con maximo aumento es erat nulla tempus vivamus in felis eu sapien, con un aumento proporcional de 8.82\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "productosVendidosUltAnio = ventas.filter(lambda x: dt.strptime(x[0],'%m/%d/%Y') > dt.strptime('01/01/2019','%d/%m/%Y'))\n",
    "productosConCantVentasOk = productosVendidosUltAnio.map(lambda x: (x[1],1)).reduceByKey(lambda x,y:x+y).filter(lambda x: x[1]>=10)\n",
    "productosConListaDePrecios = productosVendidosUltAnio.map(lambda x: (x[1],int(x[2]))).groupByKey()\n",
    "joined = (productosConCantVentasOk.join(productosConListaDePrecios).map(lambda x: (x[0],list(x[1][1])))).join(detalle)\n",
    "productoMaxAumento = joined.map(lambda x: (x[0],max(x[1][0])/min(x[1][0]),x[1][1])).reduce(lambda x,y: x if x[1]>y[1] else y)\n",
    "print(\"El producto con maximo aumento es %s, con un aumento proporcional de %.2f\"%(productoMaxAumento[2],productoMaxAumento[1]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Se tiene un RDD con las coordenadas de rectángulos de la forma (x1,x2,y1,y2). Se pide\n",
    "programar en PySpark un programa que encuentre el rectángulo de superficie mínima que\n",
    "contiene al punto (w,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(87, 11, 52, 40),\n",
       " (81, 93, 23, 4),\n",
       " (58, 52, 85, 11),\n",
       " (87, 76, 19, 54),\n",
       " (37, 38, 70, 59)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('ej4.csv').map(lambda x: tuple(int(n) for n in x.split(',')) )\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El area minima de los rectangulos que contienen al (88, 17) es 528 \n"
     ]
    }
   ],
   "source": [
    "def contiene_punto(tupla):\n",
    "    x1,x2,y1,y2 = tupla[0]\n",
    "    w,z = tupla[1]\n",
    "    return (w >= x1 and w <= x2) and (z >= y1 and z <= y2)\n",
    "\n",
    "def area(tupla):\n",
    "    x1,x2,y1,y2 = tupla[0]\n",
    "    return (x2-x1)*(y2-y1)\n",
    "\n",
    "punto = (88,17)\n",
    "rdd_a = rdd.map(lambda x: (x,punto))\n",
    "rdd_filtrado = rdd_a.filter(contiene_punto)\n",
    "rdd_area = rdd_filtrado.map(area)\n",
    "area_minima = rdd_area.reduce(lambda x,y: x if x<y else y)\n",
    "print(\"El area minima de los rectangulos que contienen al %s es %d \"%((punto),area_minima))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- UBER almacena en un cluster todos los datos sobre el movimiento y viajes de todos sus\n",
    "vehículos. Existe un proceso que nos devuelve un RDD llamado trip_summary con los\n",
    "siguientes campos: (driver_id, car_id, trip_id, customer_id, date (YYYYMMDD),\n",
    "distance_traveled), Programar usando Py Spark un programa que nos indique cual fue el\n",
    "conductor con mayor promedio de distancia recorrida por viaje para Abril de 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El conductor con mejor promedio es el 10528 con 3571.75 kilometros promedio por viaje\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "dataUber = sc.textFile(\"ej6.csv\").map(lambda x: x.split(','))\n",
    "dataUber.take(5)\n",
    "fechaLimiteInf = dt.strptime(\"2016-04-01\",'%Y-%m-%d')\n",
    "fechaLimiteSup = dt.strptime(\"2016-04-30\",'%Y-%m-%d')\n",
    "dataAbril2016 = dataUber.filter(lambda x: dt.strptime(x[4],'%Y-%m-%d') >= fechaLimiteInf and dt.strptime(x[4],'%Y-%m-%d') <= fechaLimiteSup)\n",
    "dataPorConductor = dataAbril2016.map(lambda x: (x[0],int(x[5]))).groupByKey()\n",
    "dataConPromedio = dataPorConductor.map(lambda x: (x[0],sum(list(x[1]))/len(x[1])))\n",
    "mejorPromedio = dataConPromedio.reduce(lambda x,y: x if x[1]>y[1] else y)\n",
    "print(\"El conductor con mejor promedio en Abril de 2016 es el %s con %.2f kilometros promedio por viaje\"%(mejorPromedio[0],mejorPromedio[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
